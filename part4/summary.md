# Summary

## Wrapping up

We have now built an end to end streaming pipeline. We have data flowing into Kafka from an external system and are doing real time processing on it.

We have also used the Kafka tooling to explore Kafka's main concepts which are key to build reliable, scalable and performant environments.

In this workshop, you
- Configured of Kafka tools
- Created, listed and described topic
- Consumed records with the `kafka-console-consumer.sh` tool
- Produced records with the `kafka-console-producer.sh` tool
- Used the `kafka-consumer-group.sh` tool to describe consumer groups
- Configured and ran the Kafka Connect runtime in distributed mode
- Configured and ran the `FileStreamsSourceConnector`
- Ran a Kafka Streams application

## Links to go further

- [http://kafka.apache.org/](http://kafka.apache.org/)
- [https://www.ibm.com/cloud/event-streams](https://www.ibm.com/cloud/event-streams)
- [https://developer.ibm.com/components/kafka/](https://developer.ibm.com/components/kafka/)
